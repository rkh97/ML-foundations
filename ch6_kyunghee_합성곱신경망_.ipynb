{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkh97/ML-foundations/blob/master/ch6_kyunghee_%E1%84%92%E1%85%A1%E1%86%B8%E1%84%89%E1%85%A5%E1%86%BC%E1%84%80%E1%85%A9%E1%86%B8%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE0bKzy2SIXz"
      },
      "source": [
        "# 6. 합성곱 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IDGUQbCSIX2"
      },
      "source": [
        "### 6.1 합성곱 연산과 풀링 연산\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Y4hls3SIX3"
      },
      "source": [
        "### 6.2 AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FToXRJ4MSIX4"
      },
      "outputs": [],
      "source": [
        "# 라이브러리\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UuLaVRGSIX5"
      },
      "outputs": [],
      "source": [
        "# CIFAR10 데이터 세트 불러오기\n",
        "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform = transform)\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size = 32, shuffle=True)\n",
        "\n",
        "# testset = torchvision.datasets.CIFAR10(root='./data',train=False, download=True, transform= transform)\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_W4zW-MSIX6"
      },
      "outputs": [],
      "source": [
        "# GPU 연산 체크하기\n",
        "device = torch.device(\"cuda : o\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'{device} is available')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYbYfv7VSIX6"
      },
      "outputs": [],
      "source": [
        "# AlexNet 구축하기\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential( # 순차적으로 행해지는 연산을 한 번에 묶는다. 작성 순서대로 연산이 수행됨\n",
        "            nn.Conv2d(3,64,3), nn.ReLU(), # 합성곱 연산과 풀링 연산이 행해지는 feature extraction 부분\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Conv2d(64,192,3, padding=1), nn.ReLU(), # nn.Conv2d(입력채널수, 출력채널수, 필터크기=이미지니까 3)\n",
        "            nn.MaxPool2d(2,2), # nn.MaxPool2d(필터크기, 보폭)\n",
        "            nn.Conv2d(192,384,3, padding=1), nn.ReLU(), # padding=1 : 해당 층의 입력 피쳐맵의 외각을 0으로 간 겹 둘러싼다는 의미\n",
        "            nn.Conv2d(384,256,3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(256,256,1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential( # Fully-connected layer\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256*3*3,1024), nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024,512), nn.ReLU(),\n",
        "            nn.Linear(512,10), nn.ReLU() # 10개의 클래스를 가진 데이터이므로 노드 수는 10\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1,256*3*3)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GNO6Vn9SIX7"
      },
      "outputs": [],
      "source": [
        "# 손실 함수 및 최적화 방법 정의하기\n",
        "criterion = nn.CrossEntropyLoss() # 다중 분류 문제에서는 주로 크로스엔트로피 이용\n",
        "alexnet = AlexNet().to(device) # GPU 연산을 위해 모델을 불러옴\n",
        "optimizer = optim.Adam(alexnet.parameters(),lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjsk8GBaSIX7"
      },
      "outputs": [],
      "source": [
        "# AlexNet 모델 학습\n",
        "loss_= [] # 그래프를 그리기 위한 loss 저장용 리스트\n",
        "n = len(trainloader) # 배치개수\n",
        "for epoch in range(50):\n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device) # 배치 데이터\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alexnet(inputs) # 예측값 산출\n",
        "        loss = criterion(outputs, labels) # 손실 함수 계산\n",
        "        loss.backward() # 손실함수 기준으로 역전파 선언\n",
        "        optimizer.step() # 가중치 최적화\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    loss_.append(running_loss/n)\n",
        "    print('[%d] loss : %.3f' % (epoch + 1, running_loss/len(trainloader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPQ31TMDSIX8"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_)\n",
        "plt.title(\"training loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHCOD9QSSIX8"
      },
      "outputs": [],
      "source": [
        "path = './model/cifar_alexnet.pth'\n",
        "torch.save(alexnet.state_dic(),path)\n",
        "\n",
        "alexnet = AlexNet.to(device)\n",
        "alexnet.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8lh8qajSIX8"
      },
      "source": [
        "### 6.3 ResNet\n",
        "- skip connection이란 여러 레이어를 건너 뛰어 이전 정보를 더하는 것을 의미\n",
        "- 이 하나의 과정을 묶어 만든 것이 residual block\n",
        "- ResNet은 Residual block 여러 개를 붙여놓은 모델\n",
        "- 모델 명에 붙은 숫자는 층의 개수를 의미"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZfrpxW3SIX8"
      },
      "outputs": [],
      "source": [
        "# residual block 구축하기\n",
        "class ResidualBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.in_channels - in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(self,in_channels,self.out_channels, kernel_size =3, sride=stride, padding=1, bias =False),\n",
        "            nn.BatchNorm2d(self,out_channels), # 배치 정규화를 층사이에 적용해서 학습을 빠르게 한다. 배치 정규화는 각 배치의 평균과 분산을 이용해서 데이터를 정규화하는 방법\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(self,in_channels,self.out_channels, kernel_size =3, sride=stride, padding=1, bias =False),\n",
        "            nn.BatchNorm2d(self,out_channels))\n",
        "\n",
        "        if self.stride != 1 or self.in_channels != self.out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                            nn.Conv2d(self.in_channels,self.out_channels,kernel_size=1,stride=stride, bias=False),\n",
        "                            nn.BatchNorm2d(self.out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.conv_block(x)\n",
        "        if self.stride != 1 of self.in_channels != self.out_channels:\n",
        "            x = self.downsample(x)\n",
        "        out = F.relu(x+out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeNL8KkqSIX9"
      },
      "outputs": [],
      "source": [
        "# ResNet 모델 구축하기\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_blocks, num_classes =10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.base = nn.Sequential(\n",
        "            nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU())\n",
        "        self.layer1 = self._make_layer(64,num_blocks[0],stride=1)\n",
        "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(512, num_blocks[3], stride=2)\n",
        "        self.gap = nn.AvgPool2d(4) # 필터사이즈 4\n",
        "        self.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "    def _make_layer(self, out_channels, num_blocks, stride):\n",
        "        strides =[stride]+[1]*(num_blocks-1)\n",
        "        layers=[]\n",
        "        for stride in strides:\n",
        "            block = ResidualBlock(self.in_channels, out_channels, stride)\n",
        "            layers.append(block)\n",
        "            self.in_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDGg-90RSIX9"
      },
      "outputs": [],
      "source": [
        "def forward(self, x):\n",
        "    out = self.base(x)\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = self.gap(out)\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tQx0htDSIX9"
      },
      "outputs": [],
      "source": [
        "def modeltype(model):\n",
        "    if model == 'resnet18':\n",
        "        return ResNet([2,2,2,2])\n",
        "    elif model == 'resnet34':\n",
        "        return ResNet([3,4,6,3])\n",
        "\n",
        "resnet = modeltype('resnet18').to(device)\n",
        "print(resnet)\n",
        "path = './models/cifar_resnet.pth'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}